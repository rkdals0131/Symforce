
# PGO 101 - Chapter 10 이론 강의: 카메라로 세상 보기 - Visual SLAM과 번들 조정

**강의 목표:** 이 강의를 마치면, 여러분은 Visual SLAM의 핵심 원리를 이해하고, 3D 세계가 2D 이미지로 어떻게 변환되는지를 설명할 수 있게 됩니다. 카메라의 수학적 모델을 배우고, Visual SLAM 최적화의 심장부인 **재투영 오차(Reprojection Error)**와 **번들 조정(Bundle Adjustment)**의 개념을 마스터하게 됩니다. 이 강의는 `chapter10_visual_slam_with_cameras.ipynb` 실습에서 간단한 Visual SLAM 시스템을 직접 구현하기 위한 모든 이론적 지식을 제공합니다.

---

## 1. 카메라: 3D를 2D로 담는 수학적 장치

Visual SLAM은 카메라 이미지만을 사용하여 로봇의 위치를 추정하고 지도를 작성하는 기술입니다. 이를 이해하기 위해서는 먼저 카메라가 세상을 어떻게 '보는지' 알아야 합니다.

### 개념 트리: 카메라 모델

*   **카메라 모델**
    *   **카메라 캘리브레이션 (내부 파라미터)**: 카메라 자체의 고유한 특성.
        *   **초점 거리 (Focal Length, $f_x, f_y$)**: 카메라의 '줌' 정도. 렌즈와 이미지 센서 사이의 ��상 거리.
        *   **주점 (Principal Point, $c_x, c_y$)**: 이미지 센서의 중심점. 렌즈의 광학 축이 센서와 만나는 지점.
        *   **왜곡 계수 (Distortion Coefficients)**: 렌즈의 물리적 한계로 인해 발생하는 이미지 왜곡을 보정하기 위한 값.
    *   **카메라 모델의 종류**
        *   **핀홀(Pinhole) 모델**: 왜곡이 없는 가장 이상적이고 간단한 선형 모델.
        *   **ATAN (어안, Fisheye) 모델**: 광각 렌즈의 심한 왜곡을 모델링하는 비선형 모델.
    *   **핵심 연산**
        *   **투영 (Projection)**: 3D 공간의 점 -> 2D 이미지 픽셀로 변환. **깊이 정보가 소실됨.**
        *   **역투영 (Back-projection)**: 2D 이미지 픽셀 -> 3D 공간의 **광선(Ray)**으로 변환.

> 💡 **핵심 비유**: 카메라는 3차원 공간의 한 점을 2차원 평면에 그림자로 드리우는 것과 같습니다. 그림자(2D 픽셀)만 보고 원래 물체(3D 점)의 정확한 위치를 알려면, 그림자까지의 거리(깊이, Depth) 정보가 추가로 필요합니다.

### [실습 연결]
`chapter10` 노트북의 **1. SymForce Camera Models**와 **1.1 Projection and Back-projection** 섹션에서는, SymForce의 `LinearCameraCal`, `ATANCameraCal` 클래스를 사용하여 카메라 모델을 만��고, 3D 점을 2D 픽셀로, 또는 그 반대로 변환하는 과정을 실습합니다.

---

## 2. 번들 조정 (Bundle Adjustment): Visual SLAM의 최종 보스

**번들 조정(BA)**은 Visual SLAM에서 가장 중요하고 계산량이 많은 최적화 단계입니다. 그 목표는 **모든 카메라의 자세**와 **모든 3D 랜드마크의 위치**를 동시에 최적화하여, 모든 관측 결과와의 모순을 최소화하는 것입니다.

### 재투영 오차 (Reprojection Error): 무엇을 최소화할 것인가?

번들 조정이 최소화하려는 비용 함수는 바로 **재투영 오차**의 총합입니다.

1.  현재 추정된 3D 랜드마크 위치와 카메라 자세가 있습니다.
2.  이 3D 랜드마크를 해당 카메라의 자세로 2D 이미지에 **투영(Projection)**합니다. → 이것이 **예측된 픽셀 위치**입니다.
3.  실제 이미지에서 해당 랜드마크가 관측된 픽셀 위치가 있습니다. → 이것이 **측정된 픽셀 위치**입니다.
4.  **재투영 오차** = `||예측된 픽셀 위치 - 측정된 픽셀 위치||`

이 오차가 0에 가까워진다는 것은, 우리가 추정한 3D 세계의 구조와 카메라의 궤적이 실제 이미지 관측 결과와 완벽하게 일치한다는 의미입니다.

> 💡 **핵심 비유**: 여러 명의 화가(카메���)가 같은 조각상(랜드마크)을 각자 다른 위치에서 그렸다고 상상해보세요. 번들 조정은 각 화가의 위치와 조각상의 3D 형태를 동시에 조정하여, 모든 그림이 실제 조각상의 모습과 정확히 일치하도록 만드는 과정입니다. "Bundle"은 조각상의 한 점에서 각 화가들의 눈으로 들어오는 빛의 다발을 의미합니다.

### 번들 조정의 구조

번들 조정은 거대한 포즈 그래프 최적화 문제입니다.

*   **정점 (Vertices)**:
    *   모든 카메라의 자세 (`Pose3`)
    *   모든 3D 랜드마크의 위치 (`Point3`)
*   **간선 (Edges)**:
    *   각 카메라가 랜드마크를 관측한 정보 (재투영 오차 팩터)
    *   (선택적) 카메라 간의 오도메트리 제약

이 문제는 수많은 변수를 가지므로, H 행렬의 **희소성(Sparsity)**을 활용하는 것이 매우 중요합니다. 다행히, 특정 카메라는 일부 랜드마크만 관측하므로, H 행렬은 매우 희소한 구조를 띠게 됩니다.

### [실습 연결]
`chapter10` 노트북의 **4. Visual Feature Error Functions**와 **5. Bundle Adjustment** 섹션에서는, 재투영 오차를 계산하는 `visual_feature_residual` 함수를 SymForce로 정의하고, 이를 `Factor`로 사용하여 간단한 번들 조정 문제를 설정하�� 풀어봅니다. **6. Visualizing Bundle Adjustment Results** 에서는 최적화 전/후의 3D 씬을 시각화하여 그 결과를 확인합니다.
